{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5RtmpwqNyvvw"
   },
   "source": [
    "# CS4487 Project: Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM4u04Ptyvvz"
   },
   "source": [
    "## Regarding course project\n",
    "* External training data is not allowed. Learning can only be performed on the 50,000 training images in **CIFAR10**\n",
    "* The [**CIFAR10** dataset](https://www.cs.toronto.edu/~kriz/cifar.html) was comprised of 60,000 32 Ã— 32 color photographs of objects from 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.\n",
    "* Submit the results at [Kaggle CS4487 Course Project](https://www.kaggle.com/c/cs4487cp/)\n",
    "* The second test set containing roughly 2,000 images (refer to test_data/y_test.npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KC9dhUb2yvvz"
   },
   "source": [
    "## Evaluation Criteria \n",
    "\n",
    "* ### Classification Accuaracy:\n",
    "  ### $$ Acc(f, D) = \\frac{1}{m}\\sum_{i=1}^{m}\\mathbb{I}[y^i = f(x^i)]$$\n",
    "\n",
    "* ### File Format:\n",
    "Upload a file in CSV format, such as:\n",
    "\n",
    "|         **Index**         |         **Category**        |\n",
    "|---------------------------|-----------------------------|\n",
    "| 0                         | 8                           |\n",
    "| 1                         | 4                           |\n",
    "| 2                         | 6                           |\n",
    "| 3                         | 1                           |\n",
    "| ......                    | ......                      |\n",
    "| 11999                     | 2                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlAURl9gyvv1"
   },
   "source": [
    "PyTorch Tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hEdlTSHSyvv3"
   },
   "source": [
    "---\n",
    "## Table of content (for quick jump)\n",
    "* ### [Import Library](#Import-Library)\n",
    "* ### [Data Preparation](#Data-Preparation)\n",
    "* ### [Common Functions](#Common-Functions)\n",
    "  * #### [Training Function](#Training-function)\n",
    "  * #### [Testing Function](#Testing-function)\n",
    "  * #### [Test for each category](#Test-for-each-category)\n",
    "  * #### [Save Model](#Save-Model)\n",
    "  * #### [Print Time](#Print-Time)\n",
    "  * #### [Progress Bar](#Progress-Bar)\n",
    "* ### [Dual Path Networks](#Dual-Path-Networks)\n",
    "  * #### [Training](#Train-DPN)\n",
    "  * #### [Testing](#Test-DPN)\n",
    "* ### [Run the model in project test data](#Run-the-model-in-project-test-data)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gm8PdbZpyvv4"
   },
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar2\n",
      "  Downloading https://files.pythonhosted.org/packages/16/68/adc395e0a3c86571081c8a2e2daaa5b58270f6854276a089a0e9b5fa2c33/progressbar2-3.47.0-py2.py3-none-any.whl\n",
      "Collecting python-utils>=2.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from progressbar2) (1.12.0)\n",
      "Installing collected packages: python-utils, progressbar2\n",
      "Successfully installed progressbar2-3.47.0 python-utils-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5IH1vwTyvv5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "from _datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from progressbar import *\n",
    "from sys import platform\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"win32\":\n",
    "    gd_root = \".\"  # For loacal run\n",
    "    \n",
    "else:  # run on Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    gd_root = \"gdrive/My Drive/Colab Notebooks/CS4487/Project\"\n",
    "\n",
    "gd_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_root = \".\"  # For loacal run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1A24rM-yvv8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "basic_path = \"basic_cifar_net.pth\"\n",
    "PATH_DPN = \"DPN_cifar.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBvQrtukyvwA"
   },
   "source": [
    "---\n",
    "---\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8Ar3LQxyvwB"
   },
   "source": [
    "### Read CIFAR10 data\n",
    "* The archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with cPickle.\n",
    "* Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
    "  * **data**: \n",
    "    * a 10,000 x 3,072 numpy array of uint8s. Each row of the array stores a 32 x 32 colour image. \n",
    "    * The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. \n",
    "    * The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "  * **labels**: \n",
    "    * a list of 10,000 numbers in the range 0 - 9. \n",
    "    * The number at index i indicates the label of the ith image in the array data.\n",
    "* The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:\n",
    "  * **label_names** -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. \n",
    "  * For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37XbAGx7yvwB"
   },
   "source": [
    "### Loading and normalizing CIFAR10 to dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oyQkgqNOyvwC"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DB2gBIfPyvwE"
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root=f'{gd_root}/data', train=True, download=False, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=8, \n",
    "                                           pin_memory=True\n",
    "                                          )\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=f'{gd_root}/data', train=False, download=False, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, \n",
    "                                          batch_size=32,\n",
    "                                          shuffle=False, \n",
    "                                          num_workers=8,\n",
    "                                          pin_memory=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3289,
     "status": "ok",
     "timestamp": 1576304876813,
     "user": {
      "displayName": "Tai To CHAN",
      "photoUrl": "",
      "userId": "16856483288969111373"
     },
     "user_tz": -480
    },
    "id": "iZX-q8HpyvwH",
    "outputId": "8344fa58-1354-40ea-f53b-b4c8217ca5eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(trainset)\n",
    "train_size\n",
    "test_size = len(testset)\n",
    "test_size\n",
    "train_batch_len = len(train_loader)\n",
    "train_batch_len\n",
    "test_batch_len = len(test_loader)\n",
    "test_batch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_CV6HHIyvwJ"
   },
   "outputs": [],
   "source": [
    "category_dict = {\n",
    "    'airplane': 1, \n",
    "    'automobile': 2, \n",
    "    'bird': 3, \n",
    "    'cat': 4, \n",
    "    'deer': 5, \n",
    "    'dog': 6, \n",
    "    'frog': 7, \n",
    "    'horse': 8, \n",
    "    'ship': 9, \n",
    "    'truck': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xdE57azyvwM"
   },
   "source": [
    "---\n",
    "---\n",
    "## Common Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixup \n",
    "From [Facebook AI Research](https://github.com/facebookresearch/mixup-cifar10/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if device == 'cuda':\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZQmGXmvyvwM"
   },
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_correct_rate = []\n",
    "train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qobPAnZVyvwN"
   },
   "outputs": [],
   "source": [
    "def training(epoch_num: int, model_name: str, net):\n",
    "\n",
    "#     print_time_and_msg(f\"Preparing data for {epoch_num} epoches\")\n",
    "    \n",
    "    final_loss = 0.0\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    train_bar = progress_bar(train_batch_len)\n",
    "    \n",
    "    for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader, 0):\n",
    "                        \n",
    "            if device == 'cuda':\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "            # Mixup\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, 1.0)\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            final_loss = round(running_loss / train_batch_len, 3)\n",
    "        \n",
    "        print()\n",
    "        correct_rate = correct / total\n",
    "        if epoch == 0:\n",
    "            save_model(model_name, net)\n",
    "        elif correct_rate > train_correct_rate[-1]:\n",
    "            save_model(model_name, net)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        train_bar.update(epoch)\n",
    "        \n",
    "        print_time_and_msg(f\"Trained Epoch {epoch + 1}. loss: {final_loss}. Correct rate: {correct_rate}\")\n",
    "        train_correct_rate.append(correct_rate)\n",
    "        train_loss.append(final_loss)\n",
    "            \n",
    "    print_time_and_msg(f'Finished training total {train_size} data for {epoch_num} epoches,\\nthe final loss is {final_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9e2HRpQyvwP"
   },
   "source": [
    "### Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUm3wxi-yvwQ"
   },
   "outputs": [],
   "source": [
    "def testing(net):\n",
    "    test_bar = progress_bar(test_batch_len)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ti, (inputs, targets) in enumerate(test_loader):\n",
    "            \n",
    "            if device == 'cuda':\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                \n",
    "            loss = criterion(outputs, targets)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            test_bar.update(ti)\n",
    "    print()\n",
    "    print(f'Accuracy of the network on the {len(test_loader)} test images: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1hxNc6byvwS"
   },
   "source": [
    "### Test for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6q6HaiKNyvwS"
   },
   "outputs": [],
   "source": [
    "def test_for_each(net):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for (inputs, targets) in test_loader:\n",
    "            \n",
    "            if device == 'cuda':\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                \n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == targets).squeeze()\n",
    "            for i in range(4):\n",
    "                label = targets[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    print()\n",
    "    for i in range(10):\n",
    "        print(f'Accuracy of {list(category_dict)[i]} : {round(100 * class_correct[i] / class_total[i], 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3gtWMo7yvwU"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "On_3Qd1tyvwV"
   },
   "outputs": [],
   "source": [
    "def save_model(model_name: str, net):\n",
    "    PATH_basic = f'{gd_root}/models/{model_name}'\n",
    "    torch.save(net.state_dict(), PATH_basic)\n",
    "    print_time_and_msg(f\"Saved model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t_V_DDVByvwY"
   },
   "source": [
    "### Print Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ymsb7YcJyvwZ"
   },
   "outputs": [],
   "source": [
    "def print_time_and_msg(msg: str) -> str:\n",
    "    now_time = time.time()\n",
    "    readable_time = datetime.fromtimestamp(now_time, pytz.timezone('Asia/Shanghai')).strftime(f'[%H:%M:%S] - {msg}')\n",
    "    print(readable_time, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xv6iNj0Iyvwc"
   },
   "source": [
    "### Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qFC1tPQyvwd"
   },
   "outputs": [],
   "source": [
    "def progress_bar(max_val: int):\n",
    "    bar = ProgressBar(\n",
    "        widgets=[\n",
    "            'Progress: ',\n",
    "            Percentage(), ' ', \n",
    "            Bar('#'), ' ', \n",
    "            Timer(), ' ', \n",
    "            ETA(), ' '\n",
    "        ], \n",
    "        max_value=max_val\n",
    "    )\n",
    "    return bar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_info(data: list):\n",
    "    x = [i for i in range(len(data))]\n",
    "    y = data\n",
    "    plt.plot(x, y)\n",
    "#     plt.title(title)\n",
    "    plt.xticks(np.arange(min(x), max(x)+1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uh2PBy0Myvwf"
   },
   "source": [
    "### Unpickle CIFAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1489,
     "status": "ok",
     "timestamp": 1576304904840,
     "user": {
      "displayName": "Tai To CHAN",
      "photoUrl": "",
      "userId": "16856483288969111373"
     },
     "user_tz": -480
    },
    "id": "6uz2DilZyvwg",
    "outputId": "484838c1-8b05-475d-e8fd-c0c047dc9950"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'num_cases_per_batch': 10000,\n",
       " b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unpickle_cifar10(file: str) -> dict:\n",
    "    full_name = f\"{gd_root}/data/cifar-10-batches-py/{file}\"\n",
    "    \n",
    "    with open(full_name, 'rb') as fi:\n",
    "        cifar10_dict = pickle.load(fi, encoding='bytes')\n",
    "    return cifar10_dict\n",
    "\n",
    "cifar_meta = unpickle_cifar10(\"batches.meta\")\n",
    "cifar_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDJjhugXyvxO"
   },
   "source": [
    "## Dual Path Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UlU4Y5myvxO"
   },
   "source": [
    "### Define DPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jwei3rzsyvxP"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, last_planes, in_planes, out_planes, dense_depth, stride, first_layer):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.out_planes = out_planes\n",
    "        self.dense_depth = dense_depth\n",
    "\n",
    "        self.conv1 = nn.Conv2d(last_planes, in_planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv2 = nn.Conv2d(in_planes, in_planes, kernel_size=3, stride=stride, padding=1, groups=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv3 = nn.Conv2d(in_planes, out_planes + dense_depth, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes+dense_depth)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if first_layer:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(last_planes, out_planes + dense_depth, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_planes + dense_depth)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        x = self.shortcut(x)\n",
    "        d = self.out_planes\n",
    "        out = torch.cat([x[:,:d,:,:] + out[:,:d,:,:], x[:,d:,:,:], out[:,d:,:,:]], 1)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IRALbnL1yvxR"
   },
   "outputs": [],
   "source": [
    "class DPN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(DPN, self).__init__()\n",
    "        in_planes, out_planes = cfg['in_planes'], cfg['out_planes']\n",
    "        num_blocks, dense_depth = cfg['num_blocks'], cfg['dense_depth']\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.last_planes = 64\n",
    "        self.layer1 = self._make_layer(in_planes[0], out_planes[0], num_blocks[0], dense_depth[0], stride=1)\n",
    "        self.layer2 = self._make_layer(in_planes[1], out_planes[1], num_blocks[1], dense_depth[1], stride=2)\n",
    "        self.layer3 = self._make_layer(in_planes[2], out_planes[2], num_blocks[2], dense_depth[2], stride=2)\n",
    "        self.layer4 = self._make_layer(in_planes[3], out_planes[3], num_blocks[3], dense_depth[3], stride=2)\n",
    "        self.linear = nn.Linear(out_planes[3] + (num_blocks[3] + 1) * dense_depth[3], 10)\n",
    "\n",
    "    def _make_layer(self, in_planes, out_planes, num_blocks, dense_depth, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for i,stride in enumerate(strides):\n",
    "            layers.append(Bottleneck(self.last_planes, in_planes, out_planes, dense_depth, stride, i==0))\n",
    "            self.last_planes = out_planes + (i + 2) * dense_depth\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVzlzN19yvxU"
   },
   "outputs": [],
   "source": [
    "def DPN26():\n",
    "    cfg = {\n",
    "        'in_planes': (96,192,384,768),\n",
    "        'out_planes': (256,512,1024,2048),\n",
    "        'num_blocks': (2,2,2,2),\n",
    "        'dense_depth': (16,32,24,128)\n",
    "    }\n",
    "    return DPN(cfg)\n",
    "\n",
    "def DPN92():\n",
    "    cfg = {\n",
    "        'in_planes': (96,192,384,768),\n",
    "        'out_planes': (256,512,1024,2048),\n",
    "        'num_blocks': (3,4,20,3),\n",
    "        'dense_depth': (16,32,24,128)\n",
    "    }\n",
    "    return DPN(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klwLrEFMyvxW"
   },
   "source": [
    "### Train DPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6512,
     "status": "ok",
     "timestamp": 1576304944308,
     "user": {
      "displayName": "Tai To CHAN",
      "photoUrl": "",
      "userId": "16856483288969111373"
     },
     "user_tz": -480
    },
    "id": "JikSvrm8yvxW",
    "outputId": "3655a091-8160-4789-ed14-be030c54e070"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(304, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(320, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 544, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(640, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(672, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(672, 1048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1072, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1096, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1120, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1144, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1168, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1216, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1240, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1264, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1288, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1312, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1336, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1360, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1408, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1432, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1456, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1480, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1504, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1528, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(1528, 2176, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2432, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=2560, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPN_net = DPN92()\n",
    "DPN_net.to(device)\n",
    "if device == 'cuda':\n",
    "    DPN_net = torch.nn.DataParallel(DPN_net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgrLCydtyvxZ"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(DPN_net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FsQV6evnyvxc"
   },
   "source": [
    "#### Go to [training function](#Training-function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1576305007944,
     "user": {
      "displayName": "Tai To CHAN",
      "photoUrl": "",
      "userId": "16856483288969111373"
     },
     "user_tz": -480
    },
    "id": "GsuU7Pklerei",
    "outputId": "0dc6ac9d-b7b7-4e37-8cb6-604449780dc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:41:06] - Loaded model: DPN_cifar.pth\r"
     ]
    }
   ],
   "source": [
    "model_PATH = f\"{gd_root}/models/{PATH_DPN}\"\n",
    "DPN_net.load_state_dict(torch.load(model_PATH))\n",
    "print_time_and_msg(f\"Loaded model: {PATH_DPN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoches = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11614309,
     "status": "error",
     "timestamp": 1576316660920,
     "user": {
      "displayName": "Tai To CHAN",
      "photoUrl": "",
      "userId": "16856483288969111373"
     },
     "user_tz": -480
    },
    "id": "8e6JCJy4yvxc",
    "outputId": "8c764e78-25ff-42ab-fa52-95794b36d1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:41:09] - Start training for 500 epoches\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: N/A% |                        | Elapsed Time: 0:00:00 ETA:  --:--:-- "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[22:43:54] - Trained Epoch 1. loss: 1.411. Correct rate: 0.4119\r"
     ]
    }
   ],
   "source": [
    "print_time_and_msg(f\"Start training for {epoches} epoches\\n\")\n",
    "training(epoch_num=epoches, model_name=PATH_DPN, net=DPN_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_info(train_correct_rate)\n",
    "plot_train_info(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZIZtCKlyvxe"
   },
   "source": [
    "### Test DPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1760,
     "status": "ok",
     "timestamp": 1576304959213,
     "user": {
      "displayName": "Tai To CHAN",
      "photoUrl": "",
      "userId": "16856483288969111373"
     },
     "user_tz": -480
    },
    "id": "ls91n_GDyvxf",
    "outputId": "1d94f7e7-ddb6-4ad9-cc8e-0561e7918c58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_PATH = f\"{gd_root}/models/{PATH_DPN}\"\n",
    "test_net = DPN92()\n",
    "if device == 'cuda':\n",
    "    test_net = torch.nn.DataParallel(test_net)\n",
    "    cudnn.benchmark = True\n",
    "test_net.load_state_dict(torch.load(model_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24583,
     "status": "error",
     "timestamp": 1576304986287,
     "user": {
      "displayName": "Tai To CHAN",
      "photoUrl": "",
      "userId": "16856483288969111373"
     },
     "user_tz": -480
    },
    "id": "QvEIBZnbyvxg",
    "outputId": "944788eb-ce52-43d4-fd78-99cd33eaafb0"
   },
   "outputs": [],
   "source": [
    "testing(test_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1OATaiLmyvxi"
   },
   "outputs": [],
   "source": [
    "test_for_each(test_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77WiD6JXyvxt"
   },
   "source": [
    "---\n",
    "---\n",
    "## Run the model in project test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJALJcIxyvxw"
   },
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KzaLs-wGyvxx",
    "outputId": "8f3dc205-5a92-4010-a1a0-72c07cd72070"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 3, 32, 32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_testset = np.load(f\"{gd_root}/data/test_data/y_test.npy\").astype(np.uint8)\n",
    "project_testset = np.moveaxis(project_testset, -1, 2)\n",
    "project_testset = np.moveaxis(project_testset, 2, 1)\n",
    "project_testset.shape\n",
    "type(project_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dOcu_QQyvxz"
   },
   "source": [
    "### Convert to DataLoader ([Convertion Reference](https://stackoverflow.com/questions/44429199/how-to-load-a-list-of-numpy-arrays-to-pytorch-dataset-loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEePOqX9yvx0"
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "tensor_testset = torch.Tensor(project_testset)\n",
    "the_dataset = data.TensorDataset(tensor_testset)\n",
    "project_test_loader = data.DataLoader(the_dataset, \n",
    "                                      batch_size=32,\n",
    "                                      num_workers=8,\n",
    "                                      pin_memory=True\n",
    "                                     )\n",
    "test_batch_len = len(project_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXhVXVBfyvx7"
   },
   "source": [
    "### Run the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92iuLfst-aKE"
   },
   "outputs": [],
   "source": [
    "predict_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgeSzkXSyvx8"
   },
   "outputs": [],
   "source": [
    "def run_project_test(net, model_path):\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    test_pbar = progress_bar(test_batch_len)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for index, imgs in enumerate(project_test_loader):\n",
    "            \n",
    "            imgs = torch.stack([torch.Tensor(i) for i in imgs]).squeeze()\n",
    "            \n",
    "            if device == 'cuda':\n",
    "                imgs.cuda()\n",
    "                \n",
    "            outputs = net(imgs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            for p in predicted:\n",
    "                predict_result.append(p)\n",
    "            \n",
    "            test_pbar.update(index)\n",
    "      \n",
    "    print(len(predict_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkO7pEtGyvyA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(304, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(96, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(320, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(320, 544, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(640, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(192, 544, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(672, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(672, 1048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1072, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1096, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1120, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1144, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1168, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1216, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1240, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1264, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1288, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1312, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1336, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1360, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1408, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1432, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1456, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1480, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1504, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(384, 1048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1528, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(1528, 2176, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2432, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(768, 2176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=2560, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  99% |####################### | Elapsed Time: 0:00:18 ETA:   0:00:00 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    }
   ],
   "source": [
    "model_PATH = f\"{gd_root}/models/{PATH_DPN}\"\n",
    "p_test_net = DPN92()\n",
    "if device == 'cuda':\n",
    "    p_test_net.to(device)\n",
    "    p_test_net = torch.nn.DataParallel(p_test_net)\n",
    "    cudnn.benchmark = True\n",
    "run_project_test(p_test_net, model_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Z7hl1ak-aKL",
    "outputId": "2cdfecd1-241e-49aa-a286-228b998286e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5E7gyd8yvyD"
   },
   "source": [
    "### Save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wA2cHmKyyvyE"
   },
   "outputs": [],
   "source": [
    "def save_to_csv(result: list):\n",
    "    result_df = pd.DataFrame(\n",
    "        list(predict_result),\n",
    "        columns=[\"Category\"]\n",
    "    )\n",
    "    result_df.index.name = \"Index\"\n",
    "    # result_df\n",
    "    result_df.to_csv(f\"{gd_root}/predict_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcf6hjlWyvyI"
   },
   "outputs": [],
   "source": [
    "save_to_csv(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Elytc4GGyvyL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1Tu2bqE5yvwk",
    "S15lvkBqyvwz",
    "B81yKDDJyvw2",
    "h0W9w1Dfyvw7",
    "orrJg-sjyvw-",
    "CqggjSvSyvw_",
    "UguTeLXRyvxA",
    "Gcg_NYYeyvxE",
    "OudCsGPayvxH",
    "lGFo0oTzyvxK"
   ],
   "name": "Project_Image_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
