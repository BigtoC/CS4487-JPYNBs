{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**EID:** \\_\\_\\_\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Tutorial 8: Non-Linear Dimensionality Reduction and Face Recognition\n",
    "\n",
    "In this tutorial you will use non-linear dimensionality reduction on face images, and then train a classifier for face recognition. \n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import joblib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "random.seed(100)\n",
    "rbow = plt.get_cmap('rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Pre-processing\n",
    "We first need to load the images.  We will use the same dataset as Tutorial 7. Download `olivetti_py3.pkz` from Canvas, and place it in in the same directory as this ipynb file.  _DO NOT UNZIP IT_.  Then run the following cell to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oli = datasets.fetch_olivetti_faces(data_home=\"./\")\n",
    "X = oli.data\n",
    "Y = oli.target\n",
    "img = oli.images\n",
    "imgsize = oli.images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 64x64 array of pixel values, resulting in a 4096 dimensional vector.  Run the below code to show all the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(0,400,20):\n",
    "    tmp.append( hstack(img[i:i+20]) )\n",
    "allimg = vstack(tmp)\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(allimg, cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each person is considered as one class, and there are 10 images for each class.  In total there are 40 classes (people).  The data is already vectorized and put into the matrix `X`. Now we split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into 80% train and 20% test set\n",
    "trainX, testX, trainY, testY = \\\n",
    "  model_selection.train_test_split(X, Y, \n",
    "  train_size=0.80, test_size=0.20, random_state=4487)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Dimensionality Reduction - KPCA\n",
    "The dimension of the data is too large (4096) so learning classifiers will take a long time.  Instead, our strategy is to use KPCA to reduce the dimension first and then use the KPCA weights as the representation for each image.  Run KPCA on the data using **10** principal components.  Use the RBF kernel with gamma=0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT\n",
    "# 1. decomposition.KernelPCA(n_components= , kernel= , gamma= , n_jobs= )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function will plot the basis vectors of KPCA. Run the next 2 cells to view the PCs.  The kernel PCs are a combination of similarities to points in the training set.  The PCs are visualized by showing the top 5 positive and negative training examples, along with their coefficient $\\alpha_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kbasis(model, imgsize, X):\n",
    "    KK = model.n_components\n",
    "    alphas = model.alphas_.T\n",
    "    minmax = 5\n",
    "    \n",
    "    py = KK\n",
    "    px = minmax*2\n",
    "    for i in range(KK):\n",
    "        # sort alphas\n",
    "        inds = argsort(alphas[i,:])\n",
    "\n",
    "        myi = r_[arange(-1,-minmax-1,-1), arange(minmax-1,-1,-1)]\n",
    "        myinds = inds[myi]\n",
    "        \n",
    "        for j,jj in enumerate(myinds):\n",
    "            plt.subplot(py,px,(j+1)+i*px)\n",
    "            plt.imshow(X[jj,:].reshape(imgsize), interpolation='nearest')\n",
    "            plt.gray()\n",
    "            if alphas[i,jj]<0:\n",
    "                mycol = 'b'\n",
    "            else:\n",
    "                mycol = 'r'\n",
    "            plt.title(\"{:.3f}\".format(alphas[i,jj]), fontsize=7, color=mycol)\n",
    "            if (j==0):\n",
    "                plt.ylabel('PC' + str(i+1))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function\n",
    "plt.figure(figsize=(10,12))\n",
    "plot_kbasis(kpca, imgsize, trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What is the interpretation for the KPCA basis?  What kind of faces do some of the PCs prefer?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition\n",
    "Now train a logistic classifier to do the face recognition.  Use the calculated KPCA representation as the new set of inputs.  Use cross-validation to set the hyperparameters of the classifier.  You do not need to do cross-validation for the number of components or kernel hyperparameters.  Calculate the average training and testing accuracies.  Remember to transform the test data into the KPCA representation too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT \n",
    "# 1. linear_model.LogisticRegressionCV(Cs= , cv= , n_jobs= )\n",
    "# 2. acc = metrics.accuracy_score( , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Dimensionality Reduction - ICA\n",
    "\n",
    "Next, we will use ICA to reduce the dimension.\n",
    "\n",
    "- Applying the ICA with **20** principal components as the representation for each image. \n",
    "- Using the calculated ICA representation to  train a logistic classifier to do the face recognitio. \n",
    "- Calculating the average training and testing accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT\n",
    "# 1. decomposition.FastICA(n_components=  )\n",
    "# 2. linear_model.LogisticRegressionCV(Cs= , cv= , n_jobs= )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best kernel and best number of components\n",
    "Now try different kernels (poly, RBF), kernel parameters, and number of components to get the best test accuracy using KPCA.  \n",
    "Train a logistic classifier for each one and see which dimension gives the best testing accuracy. \n",
    "Make a plots of number of components vs. test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HINT\n",
    "#1. KernelPCA(n_components=nc, kernel='rbf', gamma=, n_jobs=)\n",
    "#2. LogisticRegressionCV(Cs=, cv=, n_jobs=)\n",
    "#3. metrics.accuracy_score( , )\n",
    "\n",
    "gammas = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "ncs = [5, 10, 15, 20, 25, 30]\n",
    "nc = max(ncs)\n",
    "\n",
    "trainacc = zeros((len(gammas), len(ncs)))\n",
    "testacc  = zeros((len(gammas), len(ncs)))\n",
    "### INSERT YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HINT\n",
    "#1. KernelPCA(n_components=nc, kernel='poly', degree=, n_jobs=)\n",
    "#2. LogisticRegressionCV(Cs=, cv=, n_jobs=)\n",
    "#3. metrics.accuracy_score( , )\n",
    "degrees = [1,2,3,4,5]\n",
    "trainacc_poly = zeros((len(degrees), len(ncs)))\n",
    "testacc_poly  = zeros((len(degrees), len(ncs)))\n",
    "### INSERT YOUR CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "for i,gamma in enumerate(gammas):\n",
    "    plt.plot(ncs, trainacc[i,:], '.-', color=rbow(float(i)/len(gammas)), label=\"RBF gamma=\"+str(gamma))\n",
    "for i,d in enumerate(degrees):\n",
    "    plt.plot(ncs, trainacc_poly[i,:], '.--', color=rbow(float(i)/len(degrees)), label=\"poly deg=\"+str(d))\n",
    "plt.ylim(0,1.1)    \n",
    "\n",
    "plt.legend(loc=\"lower right\", fontsize=7)\n",
    "plt.grid(True)\n",
    "plt.subplot(1,2,2)\n",
    "for i,gamma in enumerate(gammas):\n",
    "    plt.plot(ncs, testacc[i,:], '.-', color=rbow(float(i)/len(gammas)))\n",
    "for i,d in enumerate(degrees):\n",
    "    plt.plot(ncs, testacc_poly[i,:], '.--', color=rbow(float(i)/len(degrees)))\n",
    "plt.ylim(0,1.1)    \n",
    "    \n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What is the best kernel and number of components?  View the prototypes for each compenent to see what they look like_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT\n",
    "# 1. ii = unravel_index(argmax(testacc), testacc.shape)\n",
    "# 2. gamma = gammas[ii[0]]\n",
    "# 3. plot_kbasis(kpca, imgsize, trainX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
